{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Vector Store as Retriever\n",
    "* Find the embedding that best answers your question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065e336-d054-412c-8a3f-1fbec63e1bcd",
   "metadata": {},
   "source": [
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dda8d4-80cf-4b8f-9981-94edda5e9911",
   "metadata": {},
   "source": [
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 005-retrievers.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **005-retrievers**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e766aa-f3e2-491f-be99-d0c6b700d47a",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f99504a-1b8f-4360-b342-0b81ffa06aff",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e5789-5bde-42e1-88dd-92dc8e363c24",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5514113-ddca-4ae9-9de6-0b9225b18f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef1e5c-b7e2-4a04-96c5-8f64377b8eba",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d23f4-61f5-4227-8a75-7eefde6680ee",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c573cdd8-3aff-488b-8649-4050a42e26c4",
   "metadata": {},
   "source": [
    "## Vector databases (aka vector stores): store and search embeddings\n",
    "* See the documentation page [here](https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/).\n",
    "* See the list of vector stores [here](https://python.langchain.com/v0.1/docs/integrations/vectorstores/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b5f44-5c40-4eb7-aa25-f1591b0f1580",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bbb79b-595f-44e8-b146-65152becb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8e0c5a1d-10d3-4813-a5e3-765c2127e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "loaded_document = TextLoader('./data/state_of_the_union.txt').load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "chunks_of_text = text_splitter.split_documents(loaded_document)\n",
    "\n",
    "vector_db = Chroma.from_documents(chunks_of_text, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bdbd14f2-a3ca-40db-887b-b86d65d0b22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
     ]
    }
   ],
   "source": [
    "question = \"What did the president say about the John Lewis Voting Rights Act?\"\n",
    "\n",
    "response = vector_db.similarity_search(question)\n",
    "\n",
    "print(response[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7973fcab-3edc-4764-8ecd-20329a30943a",
   "metadata": {},
   "source": [
    "## Vector Stores vs. Retrievers\n",
    "\n",
    "1. **Purpose and Functionality**:\n",
    "   - **Vector Stores**: These are specialized databases designed to store information in the form of vectors (high-dimensional data points that represent text or other information). Vector stores are primarily used for quickly searching and retrieving similar vectors based on a query vector. They are focused on efficiently handling similarity comparisons between the stored vectors and any query vector.\n",
    "   - **Retrievers**: Retrievers are more general tools that use various methods, including vector stores, to find and return relevant documents or information in response to a query. A retriever doesn't necessarily store the information itself but knows how to access and retrieve it when needed.\n",
    "\n",
    "2. **Storage vs. Retrieval**:\n",
    "   - **Vector Stores**: As the name implies, these are primarily concerned with storing data in a structured way that makes it fast and efficient to perform similarity searches.\n",
    "   - **Retrievers**: While they may utilize storage systems like vector stores, retrievers are more focused on the act of fetching the right information in response to a user's query. Their main job is to provide the end-user with the most relevant information or documents based on the input they receive.\n",
    "\n",
    "3. **Flexibility**:\n",
    "   - **Vector Stores**: These are somewhat limited in their scope to handling tasks that involve similarity searches within the stored vectors. They are a specific tool for specific types of data retrieval tasks.\n",
    "   - **Retrievers**: They can be designed to use different back-end systems (like vector stores or other databases) and can be part of larger systems that may involve more complex data processing or response generation.\n",
    "\n",
    "In summary, vector stores in LangChain are about how information is stored and efficiently accessed based on similarity, while retrievers are about using various methods (including vector stores) to actively fetch and return the right information in response to diverse queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef75d01-9170-4c07-9a3d-7f936067e85c",
   "metadata": {},
   "source": [
    "## Retriever: returns a response given a question\n",
    "\n",
    "1. **Retriever: returns a response given a question** - A retriever is a tool that provides specific pieces of information or documents when you ask a question or make a query.\n",
    "\n",
    "2. **A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store.** - A retriever works by taking a question that doesn't have a fixed format (an unstructured query) and finding relevant documents based on that question. It's a broad tool, more versatile than a vector store, which is just one way to organize information to make retrieval efficient.\n",
    "\n",
    "3. **A retriever does not need to be able to store documents, only to return (or retrieve) them.** - The main job of a retriever is to find and return documents when asked; it doesn't have to store these documents itself. It can find documents stored elsewhere.\n",
    "\n",
    "4. **Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well.** - Although many retrievers use a system called a vector store to help find the right documents quickly (a vector store organizes information into a format that's easy to search through), there are other ways to build a retriever that don't rely on this method.\n",
    "\n",
    "Overall, a retriever helps you find information you need from a large amount of data by searching through documents, and it can use different methods to do this efficiently.\n",
    "* See the documentation page [here](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/).\n",
    "* See the list of third-party retrievers [here](https://python.langchain.com/v0.1/docs/integrations/retrievers/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fc3da7-111f-428c-b897-7d4737ad4d19",
   "metadata": {},
   "source": [
    "#### Vector store as retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "47b42931-75c5-465d-a615-7e57531a18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./data/state_of_the_union.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c8753-66ab-4d99-afc2-6378e097a6f2",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f10cb2-7093-4674-b430-ed3b132e9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f5dfeb82-ac3c-4d75-895f-c4e099feedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loaded_document = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "chunks_of_text = text_splitter.split_documents(loaded_document)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vector_db = FAISS.from_documents(chunks_of_text, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b5915c97-525d-4091-a6e7-e12ed91e7d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acfc83e-6088-438b-bdc0-3c876916e190",
   "metadata": {},
   "source": [
    "## Differences .similarity_search vs. .as_retriever()\n",
    "Both methods involve finding the most relevant text based on a query, but they are structured differently and may offer different functionalities based on their implementation.\n",
    "\n",
    "#### `.similarity_search`\n",
    "\n",
    "This method directly performs a similarity search against a vector database, which in your first code snippet is managed by the `Chroma` class. The process includes:\n",
    "- Embedding the input query using the same model that was used to embed the document chunks.\n",
    "- Searching the vector database for the closest vectors to the query's embedding.\n",
    "- Returning the most relevant chunks based on their semantic similarity to the query.\n",
    "\n",
    "This method is straightforward and typically used when you need to quickly find and retrieve the text segments that best match the query.\n",
    "\n",
    "#### `.as_retriever()`\n",
    "\n",
    "This method involves a different approach:\n",
    "1. **Retriever Setup**: In the second code snippet, `vector_db.as_retriever()` converts the vector database (managed by `FAISS` in this case) into a retriever object. This object abstracts the similarity search into a retriever model that can be used in more complex retrieval-augmented generation (RAG) tasks.\n",
    "2. **Invoke Method**: The `invoke()` function on the retriever is then used to perform the query. This method can be part of a larger system where the retriever is integrated with other components (like a language model) to generate answers or further process the retrieved documents.\n",
    "\n",
    "#### Key Differences\n",
    "\n",
    "- **Flexibility**: `.as_retriever()` provides a more flexible interface that can be integrated into larger, more complex systems, potentially combining retrieval with generation (like in RAG setups). This method is beneficial in applications where the retrieved content might be used as input for further processing or answer generation.\n",
    "- **Backend Implementation**: While `.similarity_search` directly accesses the vector database, `.as_retriever()` encapsulates this access within a retriever object, which might have additional functionalities or optimizations for specific retrieval tasks.\n",
    "- **Use Cases**: The direct `.similarity_search` might be faster and more straightforward for simple query-to-document retrieval tasks. In contrast, `.as_retriever()` could be used in scenarios requiring additional steps after retrieval, like feeding the retrieved information into a language model for generating coherent and context-aware responses.\n",
    "\n",
    "Both methods are useful, but their appropriateness depends on the specific requirements of your application, such as whether you need straightforward retrieval or a more complex retrieval-augmented generation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f999f074-13c2-4fb5-b04f-9d0c7eb93cc4",
   "metadata": {},
   "source": [
    "#### Simple use without LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bfbe3f81-a42e-4638-862a-1875bca182d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retriever.invoke(\"what did he say about ketanji brown jackson?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aea950f3-26eb-496b-8561-303c78c53604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "22e24601-0892-4e50-b616-e9ed23b927c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.', metadata={'source': './data/state_of_the_union.txt'})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d303dd24-f146-42fa-9a1c-c42cc536f122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He said that Ketanji Brown Jackson is one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc24f4f-d23c-4202-992d-91b0623136ae",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 001-data-load.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 005-retrievers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af248e-6069-44b3-a2cd-a20aa3259874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
