{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611b1174-f956-47da-8d25-c991ed945473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77078e31-b204-4c1b-9a6a-9992936163ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Document Loaders\n",
    "LangChain can load data from many sources:\n",
    "* Websites.\n",
    "* Databases.\n",
    "* Youtube, Twitter.\n",
    "* Excel, Pandas, Notion, Figma, HuggingFace, Github, Etc.\n",
    "\n",
    "LangChain can load data of many types:\n",
    "* PDF.\n",
    "* HTML.\n",
    "* JSON.\n",
    "* Word, Powerpoint, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f9dc3-9307-4648-9d44-9a4c39396447",
   "metadata": {},
   "source": [
    "**Sometimes you will have to clean or prepare the data you load before you can use it.**\n",
    "<br>\n",
    "This is something Data Scientist are used to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1661660b-7088-472e-ab43-da66d4cdccd4",
   "metadata": {},
   "source": [
    "## Loading PDF documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f728ffb-2e07-4ba1-8a7b-5039b8ddec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a4a36d-560f-445c-9f5e-b727e5420848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"data/5pages.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6862dae-a147-4611-bade-e9d20e0b53e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d834db-06fd-41ad-8b19-361fe2cf5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c0517db-4f09-409b-889b-2b278e3f3ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 of 4 PDF Files \n",
      "Scan – Create – Reduce File Size  \n",
      " \n",
      " \n",
      "It is recommended that you purchase an Adobe Acrobat product that \n",
      "allows you to read, create and manipulate PDF documents.  Go to http://www.adobe.com/products/acrobat/matrix.html\n",
      " to compare \n",
      "Adobe products and features –Adobe  Acrobat Standard is sufficient. \n",
      " \n",
      " \n",
      "Scanning Documents \n",
      " \n",
      "You should only have to scan docu ments that are not electronic, and \n",
      "when you are unable to create a PDF using PDFMaker or the Print \n",
      "Command from t\n"
     ]
    }
   ],
   "source": [
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b52afe1-18f8-48f0-805f-baa0ea6794e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/5pages.pdf', 'page': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26ae0a8-1010-4819-9555-eab30da08d58",
   "metadata": {},
   "source": [
    "## Loading YouTube Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf57c5a9-2489-4b3b-9a85-6eb08172092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.document_loaders.generic import GenericLoader\n",
    "#from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "#from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain_community.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ebc7a-eda5-49ff-bf46-7763cc774dc2",
   "metadata": {},
   "source": [
    "* See the changes in the previous block of code importing the langchain_community module. Many thanks to Isabel González for the updates, you are on the right way to become an Honor Student!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960cae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yt_dlp\n",
    "# !pip install pydub\n",
    "# !pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f5f5c5-2d03-4001-8653-1857c0ea0210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=Rb9Bpw8yvTg\n",
      "[youtube] Rb9Bpw8yvTg: Downloading webpage\n",
      "[youtube] Rb9Bpw8yvTg: Downloading ios player API JSON\n",
      "[youtube] Rb9Bpw8yvTg: Downloading m3u8 information\n",
      "[info] Rb9Bpw8yvTg: Downloading 1 format(s): 140\n",
      "[download] Destination: data/youtube//LLM Apps： Overcoming the Context Window limits.m4a\n",
      "[download] 100% of    1.86MiB in 00:00:01 at 1.74MiB/s   \n",
      "[FixupM4a] Correcting container of \"data/youtube//LLM Apps： Overcoming the Context Window limits.m4a\"\n",
      "[ExtractAudio] Not converting audio data/youtube//LLM Apps： Overcoming the Context Window limits.m4a; file is already in target format m4a\n",
      "Transcribing part 1!\n",
      "Transcribing part 1!\n"
     ]
    }
   ],
   "source": [
    "url=\"https://www.youtube.com/watch?v=Rb9Bpw8yvTg\"\n",
    "save_dir=\"data/youtube/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1704a55f-aab7-4992-81d5-d2fe2bf5b701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How to overcome the context window limits? Remember that the context window is the maximum size of the context that we can give to an LLM. For example, an LLM like ChatGPT has the following context windows. The 3.5 model, the free model, supports a context window of up to 4096 tokens, approximately 3000 words or 6 pages. The model ChatGPT4 supports a context window of up to 8000 and a little bit tokens, approximately 6000 words or 12 pages. What limits does the context window impose on us? The c'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc4a32c-166a-4dab-8ca1-dc1a813f23cf",
   "metadata": {},
   "source": [
    "* **Update 06/01/2024**: We have tested the previous code and it works from our end. In case you have trouble with it, you can try the following alternative built by our soon-to-be Honor Student **Nicolás Oliveira**. It does not use the LangChain loader, but it does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a63962a-e42a-482b-8b2f-afd4c5a1b9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=Rb9Bpw8yvTg\n",
      "[youtube] Rb9Bpw8yvTg: Downloading webpage\n",
      "[youtube] Rb9Bpw8yvTg: Downloading ios player API JSON\n",
      "[youtube] Rb9Bpw8yvTg: Downloading m3u8 information\n",
      "[info] Rb9Bpw8yvTg: Downloading 1 format(s): 251\n",
      "[download] data/youtube/audio4.mp3 has already been downloaded\n",
      "[download] 100% of    2.76MiB\n",
      "[ExtractAudio] Not converting audio data/youtube/audio4.mp3; file is already in target format mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliocolomer/.pyenv/versions/3.11.4/envs/venv031524/lib/python3.11/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How to overcome the context window limits? Remember that the context window is the maximum size of the context that we can give to an LLM. For example, an LLM like chat GPT has the following context windows. The 3.5 model, the free model, supports a context window of up to 4,096 tokens, approximately 3000 words or 6 pages. The model chat GPT 4 supports a context window of up to 8,000 and a little bit tokens, approximately 6000 words or 12 pages. What limits does the context window impose on us? The context window prevents us from doing things like asking chat GPT to summarize a 100 page report asking chat GPT to use a large database. If we try to do that, chat GPT is going to complete. I cannot do that. The context window I have is smaller than the size of the data you are trying to give me. For us, as LLM application developers, to overcome the limitation of the context window of the functional LLM is extremely important. How to overcome the context window limits is one of the important things we deal with in our training programs. This particular content is exclusive to our training programs students.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from yt_dlp import YoutubeDL\n",
    "import whisper\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=Rb9Bpw8yvTg\"\n",
    "save_dir = \"data/youtube/\"\n",
    "audio_file = os.path.join(save_dir, \"audio4.mp3\")\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "def download_audio(url, save_path):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': save_path,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "\n",
    "download_audio(url, audio_file)\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result['text']\n",
    "\n",
    "transcription = transcribe_audio(\"data/youtube/audio4.mp3\")\n",
    "print(transcription)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c172a2eb-b34d-4788-a9bc-2a783b7698ea",
   "metadata": {},
   "source": [
    "## Loading websites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0258fba-d74b-4622-8843-16c0ee242f65",
   "metadata": {},
   "source": [
    "**Option 1: Web Base Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fe6e6-958e-4d91-bd3c-c9301a7d86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://aiaccelera.com/100-ai-startups-100-llm-apps-that-have-earned-500000-before-their-first-year-of-existence/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c66ac3-76ce-4ad1-8645-64f7bdd72be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671c8c2-5cc3-4bf0-85cc-5db6587fb7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640143f0-c75e-4c2d-9d1d-dfc3610b1afb",
   "metadata": {},
   "source": [
    "**Option 2: Unstructured HTML Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17828c2-1877-48ee-b216-39cfd7dc2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f084e39-5d10-49f9-ac04-3ae75a8ff4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredHTMLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a54b62-e906-4b74-ac31-b2bd06a49e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(\"data/_100 AI Startups__ 100 LLM Apps that have earned $500,000 before their first year of existence.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18453986-74d6-4e2b-a278-93de52638397",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab24514-2bca-4d7c-bf40-f5ee359df363",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875f549-7dd7-4a29-b4dd-ea6ed76c438e",
   "metadata": {},
   "source": [
    "**Option 3: Beautiful Soup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a113e5-636c-408d-ac5a-99f7a8f5c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b58a8b0-9526-4669-a6c7-fac7af6b3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685470d-e7e3-438e-b104-3cb0186cda45",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://aiaccelera.com/ai-consulting-for-businesses/\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4412900-4813-48fc-b37a-33727e3b361a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
